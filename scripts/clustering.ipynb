{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Sets Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_categorical_features = pd.read_pickle(\"non_conforming_categorical_features.pkl\")\n",
    "non_conforming_categorical_features = non_conforming_categorical_features.drop(columns='case:concept:name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_numerical_features = pd.read_pickle(\"non_conforming_numerical_features.pkl\")\n",
    "non_conf_idx = non_conforming_numerical_features[[\"case:concept:name\"]].copy()\n",
    "non_conforming_numerical_features = non_conforming_numerical_features.drop(columns='case:concept:name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_log = pd.read_pickle(\"filtered-non-conforminlog.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_num_scaled = scaler.fit_transform(non_conforming_numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans_3_labels = kmeans_3.fit_predict(X_num_scaled)\n",
    "\n",
    "kmeans_4 = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans_4_labels = kmeans_4.fit_predict(X_num_scaled)\n",
    "\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans_5_labels = kmeans_5.fit_predict(X_num_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_num_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain (numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "\n",
    "similarity_matrix = cosine_similarity(X_num_scaled)\n",
    "\n",
    "G_num = nx.from_numpy_array(similarity_matrix)\n",
    "\n",
    "louvain_num_clusters = louvain_communities(G_num, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_cat_encoded = encoder.fit_transform(non_conforming_categorical_features).toarray()\n",
    "\n",
    "jaccard_sim = 1 - pairwise_distances(X_cat_encoded, metric='jaccard')\n",
    "\n",
    "G_cat = nx.from_numpy_array(jaccard_sim)\n",
    "louvain_cat_clusters = louvain_communities(G_cat, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(name, labels, data=None, is_graph=False, graph=None):\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    if is_graph:\n",
    "        from networkx.algorithms.community.quality import modularity\n",
    "        communities = [set(np.where(labels == i)[0]) for i in np.unique(labels)]\n",
    "        mod_score = modularity(graph, communities)\n",
    "        sil_score = None\n",
    "    else:\n",
    "        mod_score = None\n",
    "        if len(np.unique(labels)) > 1:\n",
    "            sil_score = silhouette_score(data, labels)\n",
    "        else:\n",
    "            sil_score = None \n",
    "\n",
    "    cluster_sizes = pd.Series(labels).value_counts().to_dict()\n",
    "\n",
    "    return {\n",
    "        'Method': name,\n",
    "        'Clusters': len(np.unique(labels)),\n",
    "        'Silhouette': sil_score,\n",
    "        'Modularity': mod_score,\n",
    "        'Cluster Sizes': cluster_sizes\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "results.append(evaluate_clustering('KMeans_3', kmeans_3_labels, data=X_num_scaled))\n",
    "results.append(evaluate_clustering('KMeans_4', kmeans_4_labels, data=X_num_scaled))\n",
    "results.append(evaluate_clustering('KMeans_5', kmeans_5_labels, data=X_num_scaled))\n",
    "\n",
    "results.append(evaluate_clustering('DBSCAN', dbscan_labels, data=X_num_scaled))\n",
    "\n",
    "louvain_num_labels = np.zeros(len(X_num_scaled), dtype=int)\n",
    "for i, group in enumerate(louvain_num_clusters):\n",
    "    for node in group:\n",
    "        louvain_num_labels[node] = i\n",
    "results.append(evaluate_clustering('Louvain (Numerical)', louvain_num_labels, is_graph=True, graph=G_num))\n",
    "\n",
    "louvain_cat_labels = np.zeros(len(X_cat_encoded), dtype=int)\n",
    "for i, group in enumerate(louvain_cat_clusters):\n",
    "    for node in group:\n",
    "        louvain_cat_labels[node] = i\n",
    "results.append(evaluate_clustering('Louvain (Categorical)', louvain_cat_labels, is_graph=True, graph=G_cat))\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = {}\n",
    "for i, community in enumerate(louvain_num_clusters):\n",
    "    for node in community:\n",
    "        node_labels[node] = i\n",
    "\n",
    "node_colors = [node_labels[n] for n in G_num.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_cat_labels = {}\n",
    "for i, community in enumerate(louvain_cat_clusters):\n",
    "    for node in community:\n",
    "        node_cat_labels[node] = i\n",
    "\n",
    "node_cat_colors = [node_cat_labels[n] for n in G_cat.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10), facecolor='white')\n",
    "pos = nx.spring_layout(G_num, seed=42)\n",
    "\n",
    "nx.draw_networkx_nodes(G_num, pos, node_color=node_colors, cmap=plt.cm.tab10, node_size=40, alpha=0.8)\n",
    "nx.draw_networkx_edges(G_num, pos, alpha=0.05, width=0.5)\n",
    "plt.title(\"Louvain Graph Clustering\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label_series = pd.Series(node_labels).sort_index()\n",
    "\n",
    "non_conforming_numerical_features['cluster'] = cluster_label_series.values\n",
    "\n",
    "non_conforming_categorical_features['cluster'] = cluster_label_series.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_numerical_features.to_pickle(\"clustered_non_conforming_numerical2.pkl\")\n",
    "non_conforming_categorical_features.to_pickle(\"clustered_non_conforming_categorical2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create & Export Sub-Eventlogs From Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_idx[\"cluster\"] = cluster_label_series.values\n",
    "\n",
    "non_conforming_log_with_clusters = non_conforming_log.merge(\n",
    "    non_conf_idx,\n",
    "    on='case:concept:name',\n",
    "    how='inner'  \n",
    ")\n",
    "\n",
    "cluster_0_log = non_conforming_log_with_clusters[\n",
    "    non_conforming_log_with_clusters['cluster'] == 0\n",
    "]\n",
    "\n",
    "cluster_1_log = non_conforming_log_with_clusters[\n",
    "    non_conforming_log_with_clusters['cluster'] == 1\n",
    "]\n",
    "\n",
    "cluster_2_log = non_conforming_log_with_clusters[\n",
    "    non_conforming_log_with_clusters['cluster'] == 2\n",
    "]\n",
    "\n",
    "non_conforming_cluster_0_log = cluster_0_log.drop(columns='cluster')\n",
    "non_conforming_cluster_1_log = cluster_1_log.drop(columns='cluster')\n",
    "non_conforming_cluster_2_log = cluster_2_log.drop(columns='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_cluster_0_log.to_pickle(\"non_conforming_cluster_0_log.pkl\")\n",
    "non_conforming_cluster_1_log.to_pickle(\"non_conforming_cluster_1_log.pkl\")\n",
    "non_conforming_cluster_2_log.to_pickle(\"non_conforming_cluster_2_log.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
