{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction: Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Log Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_log_df = pd.read_pickle(\"filtered-non-conforminlog.pkl\")\n",
    "conforming_log_df  = pd.read_pickle(\"conforming-log.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normative Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"\"\n",
    "normative_petri_net = pm4py.read_pnml(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-In pm4py Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_initial_features(event_log):\n",
    "    features_df = pm4py.extract_features_dataframe(\n",
    "        event_log,\n",
    "        activity_key='concept:name',\n",
    "        case_id_key='case:concept:name',\n",
    "        timestamp_key='time:timestamp',\n",
    "        str_tr_attr=[], \t\n",
    "        num_tr_attr=[\"Amount\", \"RequestedAmount\", \"OriginalAmount\", \"Permit RequestedBudget\", \"AdjustedAmount\"],\n",
    "        str_ev_attr=['org:role'],\n",
    "        include_case_id=True\n",
    "    )\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_init_features_df = extract_initial_features(non_conforming_log_df)\n",
    "conf_init_features_df = extract_initial_features(conforming_log_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_floats_to_int64(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    float_cols = df_copy.select_dtypes(include=['float32', 'float64']).columns\n",
    "    \n",
    "    for col in float_cols:      \n",
    "        df_copy[col] = df_copy[col].astype('int64')\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_init_features_df = convert_floats_to_int64(non_conf_init_features_df)\n",
    "conf_init_features_df = convert_floats_to_int64(conf_init_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintain Uniform Dataframes (conforming vs non-conforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_fill_missing_columns(df_1, df_2):   \n",
    "    all_columns = sorted(set(df_1.columns).union(df_2.columns))\n",
    "    \n",
    "    df_1_all_columns = df_1.reindex(columns=all_columns, fill_value=0)\n",
    "    df_2_all_columns = df_2.reindex(columns=all_columns, fill_value=0)\n",
    "\n",
    "    return df_1_all_columns, df_2_all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_full_init_features_df, conf_init_full_features_df = add_n_fill_missing_columns(non_conf_init_features_df, conf_init_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Numerical Values to Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_to_bin(\n",
    "    df_list,                       \n",
    "    columns_to_bin,                \n",
    "    n_bins=4,                      \n",
    "    bin_labels=None,               \n",
    "    strategy='quantile',           \n",
    "    drop_original=True,            \n",
    "    custom_bins=None              \n",
    "):\n",
    "\n",
    "    if bin_labels is None:\n",
    "        bin_labels = [f'bin_{i+1}' for i in range(n_bins)]\n",
    "    \n",
    "    if custom_bins is None:\n",
    "        custom_bins = {}\n",
    "\n",
    "    combined = pd.concat(df_list, axis=0)\n",
    "\n",
    "    bin_edges = {}\n",
    "\n",
    "    for col in columns_to_bin:\n",
    "        if strategy == 'quantile':\n",
    "            _, bins = pd.qcut(combined[col], q=n_bins, retbins=True, duplicates='drop')\n",
    "        elif strategy == 'uniform':\n",
    "            if col in custom_bins:\n",
    "                bins = custom_bins[col]\n",
    "            else:\n",
    "                _, bins = pd.cut(combined[col], bins=n_bins, retbins=True)\n",
    "        else:\n",
    "            raise ValueError(\"strategy must be 'quantile' or 'uniform'\")\n",
    "\n",
    "        bin_edges[col] = bins\n",
    "\n",
    "        updated_dfs = []\n",
    "        for df in df_list:\n",
    "            df_copy = df.copy()\n",
    "            df_copy[col + '_bin'] = pd.cut(\n",
    "                df_copy[col],\n",
    "                bins=bins,\n",
    "                labels=bin_labels[:len(bins)-1],\n",
    "                include_lowest=True\n",
    "            )\n",
    "\n",
    "            if drop_original:\n",
    "                df_copy = df_copy.drop(columns=col)\n",
    "\n",
    "            updated_dfs.append(df_copy)\n",
    "\n",
    "        df_list = updated_dfs\n",
    "\n",
    "    return df_list, bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [non_conf_full_init_features_df, conf_init_full_features_df]\n",
    "\n",
    "numerical_cols = [\n",
    "    'case:Permit RequestedBudget',\n",
    "    'case:AdjustedAmount',\n",
    "    'case:OriginalAmount',\n",
    "    'case:Amount',\n",
    "    'case:RequestedAmount'\n",
    "]\n",
    "\n",
    "[non_conf_binned_df, conf_binned_df], bin_info = numerical_to_bin(\n",
    "    df_list = dfs,\n",
    "    columns_to_bin = numerical_cols,\n",
    "    n_bins = 4,\n",
    "    bin_labels = ['very_low', 'low', 'high', 'very_high'],\n",
    "    strategy = 'quantile',\n",
    "    drop_original = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Encoding (0/1) to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_catergorical(df):\n",
    "\n",
    "    role_cols = [col for col in df.columns if col.startswith(\"org:role_\")]\n",
    "\n",
    "    features_categorical = df.copy()\n",
    "\n",
    "    for col in role_cols:\n",
    "        features_categorical[col] = df[col].map(lambda x: 'present' if x == 1 else 'absent')\n",
    "\n",
    "    return features_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_cat_df = one_hot_to_catergorical(conf_binned_df)\n",
    "non_conf_cat_df = one_hot_to_catergorical(non_conf_binned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Case Level Categorical Attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categorical_features(event_log, df):\n",
    "    trace_categorical_attributes_df = event_log.groupby(\"case:concept:name\").agg({\n",
    "        \"case:Permit BudgetNumber\": \"first\",\n",
    "        \"case:Permit OrganizationalEntity\": \"first\", \n",
    "        \"case:Permit ProjectNumber\": \"first\", \n",
    "        \"case:BudgetNumber\": \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "    categorical_features_df = pd.merge(df, trace_categorical_attributes_df, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return categorical_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_cat_features_df = add_categorical_features(non_conforming_log_df, non_conf_cat_df)\n",
    "conf_cat_features_df = add_categorical_features(conforming_log_df, conf_cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Event Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_frequency_features(event_log, df):\n",
    "    frequency_table = event_log.groupby([\"case:concept:name\", \"concept:name\"]).size().unstack(fill_value=0)\n",
    "    frequency_table = frequency_table.reset_index()\n",
    "\n",
    "    event_freqency_features_df = pd.merge(df, frequency_table, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return event_freqency_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_ev_freq_features_df = add_event_frequency_features(non_conforming_log_df, non_conf_cat_features_df)\n",
    "conf_ev_freq_features_df = add_event_frequency_features(conforming_log_df, conf_cat_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintain Uniform Dataframes (conforming vs non-conforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_full_ev_freq_features_df, conf_full_ev_freq_features_df = add_n_fill_missing_columns(non_conf_ev_freq_features_df, conf_ev_freq_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Numerical to Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_values_to_labels(df, columns, mappings):\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    value_map = dict(mappings)\n",
    "\n",
    "    for col in columns:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].map(value_map)\n",
    "        else:\n",
    "            print(f\"Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = non_conf_full_ev_freq_features_df.select_dtypes(include='int64').columns.tolist()\n",
    "value_map = [(0, 'Never'), (1, 'Once'), (2, 'Twice'), (3, 'Three times'), (4, 'Four Times'), (5, 'Five Times'), (6, 'Six Times')]\n",
    "\n",
    "non_conf_cat_freq_features_df = map_values_to_labels(non_conf_full_ev_freq_features_df, numeric_cols, value_map)\n",
    "conf_cat_freq_features_df = map_values_to_labels(conf_full_ev_freq_features_df, numeric_cols, value_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trace_fitness_metric(event_log, df):\n",
    "\n",
    "    from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "    fitness_scores = []\n",
    "\n",
    "    for case_id in df[\"case:concept:name\"]:\n",
    "        trace_df = event_log[event_log[\"case:concept:name\"] == case_id]\n",
    "\n",
    "        sublog = log_converter.apply(trace_df, variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "\n",
    "        fitness = pm4py.fitness_token_based_replay(\n",
    "        sublog,\n",
    "        normative_petri_net[0],\n",
    "        normative_petri_net[1],\n",
    "        normative_petri_net[2],\n",
    "        activity_key='concept:name',\n",
    "        case_id_key='case:concept:name',\n",
    "        timestamp_key='time:timestamp'\n",
    "        )\n",
    "\n",
    "        fitness_value = fitness.get(\"average_trace_fitness\")\n",
    "        fitness_scores.append((case_id, fitness_value))\n",
    "\n",
    "    fitness_df = pd.DataFrame(fitness_scores, columns=[\"case:concept:name\", \"token_fitness\"])\n",
    "\n",
    "    features_fit_df = df.merge(fitness_df, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return features_fit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_fit_features_df = add_trace_fitness_metric(non_conforming_log_df, non_conf_cat_freq_features_df)\n",
    "conf_fit_features_df = add_trace_fitness_metric(conforming_log_df, conf_cat_freq_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Numerical Values to Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [non_conf_fit_features_df, conf_fit_features_df]\n",
    "\n",
    "num_cols = ['token_fitness']\n",
    "\n",
    "[non_conf_fit_binned_df2, conf_fit_binned_df2], bin_info2 = numerical_to_bin(\n",
    "    df_list = dfs,\n",
    "    columns_to_bin = num_cols,\n",
    "    n_bins = 4,\n",
    "    bin_labels = ['very_low', 'low', 'high', 'very_high'],\n",
    "    strategy = 'quantile',\n",
    "    drop_original = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [non_conf_fit_features_df, conf_fit_features_df]\n",
    "\n",
    "custom_bins = {\n",
    "    'token_fitness': [0.7, 0.8, 0.85, 0.95, 1.01]\n",
    "}\n",
    "\n",
    "[non_conf_fit_binned_df, conf_fit_binned_df], bin_info = numerical_to_bin(\n",
    "    df_list = dfs,\n",
    "    columns_to_bin = ['token_fitness'],\n",
    "    n_bins = 4,\n",
    "    bin_labels = ['very_low', 'low', 'high', 'very_high'],\n",
    "    strategy = 'uniform',\n",
    "    custom_bins = custom_bins,\n",
    "    drop_original = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace Duration & Event Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trace_duration_n_event_count(event_log, df):\n",
    "\n",
    "    trace_duration_df = event_log.groupby(\"case:concept:name\")[\"time:timestamp\"].agg(\n",
    "        trace_start=\"min\",\n",
    "        trace_end=\"max\"\n",
    "    ).reset_index()\n",
    "\n",
    "    trace_duration_df[\"trace_duration_days\"] = (trace_duration_df[\"trace_end\"] - trace_duration_df[\"trace_start\"]).dt.total_seconds() / (60 * 60 * 24)\n",
    "\n",
    "    trace_event_count_df = event_log.groupby(\"case:concept:name\").size().reset_index(name=\"num_events\")\n",
    "\n",
    "    features_duration_df = df.merge(trace_duration_df[[\"case:concept:name\", \"trace_duration_days\"]], on=\"case:concept:name\", how=\"left\")\n",
    "    features_ev_count_df = features_duration_df.merge(trace_event_count_df, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return features_ev_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_duration_n_count_features_df = add_trace_duration_n_event_count(non_conforming_log_df, non_conf_fit_binned_df)\n",
    "conf_duration_n_count_features_df = add_trace_duration_n_event_count(conforming_log_df, conf_fit_binned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Numerical Values to Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [non_conf_duration_n_count_features_df, conf_duration_n_count_features_df]\n",
    "\n",
    "[non_conf_duration_n_count_binned_df, conf_duration_n_count_binned_df], bin_info = numerical_to_bin(\n",
    "    df_list = dfs,\n",
    "    columns_to_bin = ['trace_duration_days', 'num_events'],\n",
    "    n_bins = 4,\n",
    "    bin_labels = ['very_low', 'low', 'high', 'very_high'],\n",
    "    strategy = 'quantile',\n",
    "    drop_original=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "def apply_ordered_binning_dtype(df, suffix='_bin', categories=None):\n",
    "\n",
    "    if categories is None:\n",
    "        categories = ['very_low', 'low', 'high', 'very_high']\n",
    "\n",
    "    ordinal_type = CategoricalDtype(categories=categories, ordered=True)\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for col in df_copy.columns:\n",
    "        if col.endswith(suffix):\n",
    "            df_copy[col] = df_copy[col].astype(ordinal_type)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_final_features_df = apply_ordered_binning_dtype(non_conf_duration_n_count_binned_df)\n",
    "conf_final_features_df = apply_ordered_binning_dtype(conf_duration_n_count_binned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Non-conforming feature set is of shape {non_conf_final_features_df.shape}\")\n",
    "print(f\"Conforming feature set is of shape {conf_final_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_final_features_df.to_pickle(\"non_conforming_categorical_features.pkl\")\n",
    "conf_final_features_df.to_pickle(\"conforming_categorical_features.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
