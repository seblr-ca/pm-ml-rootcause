{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Log Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conforming_log_df = pd.read_pickle(\"filtered-non-conforminlog.pkl\")\n",
    "conforming_log_df  = pd.read_pickle(\"conforming-log.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normative Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"\"\n",
    "normative_petri_net = pm4py.read_pnml(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_initial_features(event_log):\n",
    "    features_df = pm4py.extract_features_dataframe(\n",
    "        event_log,\n",
    "        activity_key='concept:name',\n",
    "        case_id_key='case:concept:name',\n",
    "        timestamp_key='time:timestamp',\n",
    "        str_tr_attr=[], \t\n",
    "        num_tr_attr=[\"Amount\", \"RequestedAmount\", \"OriginalAmount\", \"Permit RequestedBudget\", \"AdjustedAmount\"],\n",
    "        str_ev_attr=['org:role'],\n",
    "        include_case_id=True\n",
    "    )\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_init_features_df = extract_initial_features(non_conforming_log_df)\n",
    "conf_init_features_df = extract_initial_features(conforming_log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_init_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_categorical_features(event_log, df):\n",
    "    trace_categorical_attributes_df = event_log.groupby(\"case:concept:name\").agg({\n",
    "        \"case:Permit BudgetNumber\": \"first\",\n",
    "        \"case:Permit OrganizationalEntity\": \"first\", \n",
    "        \"case:Permit ProjectNumber\": \"first\", \n",
    "        \"case:BudgetNumber\": \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "    categorical_features_df = pd.merge(df, trace_categorical_attributes_df, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return categorical_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_cat_features_df = add_categorical_features(non_conforming_log_df, non_conf_init_features_df)\n",
    "conf_cat_features_df = add_categorical_features(conforming_log_df, conf_init_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_frequency_features(event_log, df):\n",
    "    frequency_table = event_log.groupby([\"case:concept:name\", \"concept:name\"]).size().unstack(fill_value=0)\n",
    "    frequency_table = frequency_table.reset_index()\n",
    "\n",
    "    event_freqency_features_df = pd.merge(df, frequency_table, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return event_freqency_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_ev_freq_features_df = add_event_frequency_features(non_conforming_log_df, non_conf_cat_features_df)\n",
    "conf_ev_freq_features_df = add_event_frequency_features(conforming_log_df, conf_cat_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trace_fitness_metric(event_log, df):\n",
    "\n",
    "    from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "    fitness_scores = []\n",
    "\n",
    "    for case_id in df[\"case:concept:name\"]:\n",
    "        trace_df = event_log[event_log[\"case:concept:name\"] == case_id]\n",
    "\n",
    "        sublog = log_converter.apply(trace_df, variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "\n",
    "        fitness = pm4py.fitness_token_based_replay(\n",
    "        sublog,\n",
    "        normative_petri_net[0],\n",
    "        normative_petri_net[1],\n",
    "        normative_petri_net[2],\n",
    "        activity_key='concept:name',\n",
    "        case_id_key='case:concept:name',\n",
    "        timestamp_key='time:timestamp'\n",
    "        )\n",
    "\n",
    "        fitness_value = fitness.get(\"average_trace_fitness\")\n",
    "        fitness_scores.append((case_id, fitness_value))\n",
    "\n",
    "    fitness_df = pd.DataFrame(fitness_scores, columns=[\"case:concept:name\", \"token_fitness\"])\n",
    "\n",
    "    features_fit_df = df.merge(fitness_df, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return features_fit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_ev_freq_features_df = add_trace_fitness_metric(non_conforming_log_df, non_conf_ev_freq_features_df)\n",
    "conf_ev_freq_features_df = add_trace_fitness_metric(conforming_log_df, conf_ev_freq_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(non_conf_ev_freq_features_df[\"token_fitness\"], bins=20, kde=True, color=\"skyblue\")\n",
    "\n",
    "plt.title(\"Distribution of Token-Based Fitness Scores per Trace\")\n",
    "plt.xlabel(\"Token Fitness Score\")\n",
    "plt.ylabel(\"Number of Traces\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace Duration & Event Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trace_duration_n_event_count(event_log, df):\n",
    "\n",
    "    trace_duration_df = event_log.groupby(\"case:concept:name\")[\"time:timestamp\"].agg(\n",
    "        trace_start=\"min\",\n",
    "        trace_end=\"max\"\n",
    "    ).reset_index()\n",
    "\n",
    "    trace_duration_df[\"trace_duration_days\"] = (trace_duration_df[\"trace_end\"] - trace_duration_df[\"trace_start\"]).dt.total_seconds() / (60 * 60 * 24)\n",
    "\n",
    "    trace_event_count_df = event_log.groupby(\"case:concept:name\").size().reset_index(name=\"num_events\")\n",
    "\n",
    "    features_duration_df = df.merge(trace_duration_df[[\"case:concept:name\", \"trace_duration_days\"]], on=\"case:concept:name\", how=\"left\")\n",
    "    features_ev_count_df = features_duration_df.merge(trace_event_count_df, on=\"case:concept:name\", how=\"left\")\n",
    "\n",
    "    return features_ev_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_duration_n_count_features_df = add_trace_duration_n_event_count(non_conforming_log_df, non_conf_ev_freq_features_df)\n",
    "conf_duration_n_count_features_df = add_trace_duration_n_event_count(conforming_log_df, conf_ev_freq_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_to_label(df):\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_cols = ['case:Permit BudgetNumber', \n",
    "                'case:Permit OrganizationalEntity', \n",
    "                'case:Permit ProjectNumber', \n",
    "                'case:BudgetNumber']\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for col in label_cols:\n",
    "        df[col + '_le'] = le.fit_transform(df[col])\n",
    "        df.drop(columns=col, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_complete_features_df = encode_categorical_to_label(non_conf_duration_n_count_features_df)\n",
    "conf_complete_features_df = encode_categorical_to_label(conf_duration_n_count_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all possible columns from both sets\n",
    "all_columns = set(non_conf_complete_features_df.columns).union(conf_complete_features_df.columns)\n",
    "\n",
    "# Reindex both with the full column set\n",
    "non_conf_final_features_df = non_conf_complete_features_df.reindex(columns=all_columns, fill_value=0)\n",
    "conf_final_features_df = conf_complete_features_df.reindex(columns=all_columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Non-conforming feature set is of shape {non_conf_final_features_df.shape}\")\n",
    "print(f\"Conforming feature set is of shape {conf_final_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_conf_final_features_df.to_pickle(\"non_conforming_numerical_features.pkl\")\n",
    "conf_final_features_df.to_pickle(\"conforming_numerical_features.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
